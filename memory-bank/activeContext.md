#  Active Context

## Focus actuel (mis √† jour 2026-02-19)

### Ontologie general.yaml v1.1 ‚Äî R√©duction "Other" REFERENTIEL v1.3.7 (SESSION COURANTE ‚Äî 2026-02-19)

**Probl√®me identifi√©** : La m√©moire REFERENTIEL (2727 entit√©s, 20 docs, ontologie `general`) contenait **299 entit√©s "Other" (11%)**, principalement issues de textes r√©glementaires : NIS2 (107), rapport NEURONES (90), DORA (67), PAMS ANSSI (20), SecNumCloud (7), HDS (6).

**Analyse** : Script `analyze_entities.py` + `analyze_others.py` + script REST ad hoc pour examiner les 299 "Other" par document source. Cat√©gorisation en **14 patterns** : articles de loi (~120), secteurs r√©glement√©s (~30), stakeholders RSE (~20), sanctions (~15), deadlines/dur√©es (~20), r√©solutions AG (~15), impacts RSE (~12), rapports (~8), zones s√©curit√© PAMS (~14), qualifications ANSSI (~4), r√¥les (~3), acronymes (~8), gouvernance (~10), composants infra (~2).

**Corrections ontologie `general.yaml` v1.0 ‚Üí v1.1** :
- **+4 types d'entit√©s** (24‚Üí28) : `LegalProvision` (articles, consid√©rants, annexes), `Sector` (secteurs NIS2/DORA/NACE), `Sanction` (amendes, astreintes, suspensions), `Stakeholder` (parties prenantes RSE)
- **+2 types de relations** (22‚Üí24) : `APPLIES_TO` (r√©glementation‚Üísecteur), `IMPOSES` (provision‚Üísanction)
- **~50 lignes de `special_instructions`** : r√®gles textes r√©glementaires, r√®gles RSE/mat√©rialit√©, 15 mappings obligatoires additionnels (qualif ANSSI‚ÜíCertification, rapports‚ÜíEvidence, zones‚ÜíTopic, comit√©s‚ÜíOrganization, r√©unions‚ÜíAction, r√¥les non nomm√©s‚Üíignorer, acronymes‚ÜíDefinition, deadlines/dur√©es/fr√©quences‚Üíint√©gr√©s, status‚Üíignorer)
- **+1 exemple d'extraction** r√©glementaire, `priority_entities` +LegalProvision +Sanction

**Action requise** : Red√©ployer en production (`git pull && docker compose build mcp-memory && docker compose up -d`) puis r√©-ing√©rer les 7 documents probl√©matiques avec `--force`.

---

### Qualit√© ontologies ‚Äî R√©duction "Other" √† 0% (SESSION COURANTE ‚Äî 2026-02-18)

**Probl√®me identifi√©** : L'ingestion de `docs/` (110 docs) produisait **159 entit√©s "Other"** (11.6% de 1376), et PRESALES avait 71 "Other". Le LLM inventait des types non d√©finis dans les ontologies (MonetaryAmount, Duration, Endpoint, Licence, Feature, Priority, etc.) qui tombaient en "Other".

**Analyse** : Script `analyze_others.py` cat√©gorise les 159 "Other" de DOCS en :
- **√Ä ajouter** (~13%): Role (RBAC), SLALevel (P1-P5, Impact, Criticit√©) ‚Äî types utiles absents
- **√Ä mapper** (~38%): Endpoint‚ÜíAPI, Licence‚ÜíPricingModel, HA‚ÜíTechnology, Feature‚ÜíNetworkComponent
- **√Ä exclure** (~25%): CLI flags, variables, erreurs, chemins, param√®tres API
- **√Ä int√©grer** (~24%): Dur√©es, langues ‚Üí dans le nom de l'entit√© parente

**Corrections ontologie `cloud.yaml` v1.1 ‚Üí v1.2** :
- **+2 entity types** : `Role` (IAM/RBAC), `SLALevel` (P1-P5, Impact I1-I3, Criticit√© C1-C3)
- **+50 lignes de `special_instructions`** avec : 12 mappings obligatoires (‚ö†Ô∏è "Ne cr√©e JAMAIS de type X"), 8 cat√©gories d'exclusion, r√®gle de qualit√© des noms

**Corrections ontologie `presales.yaml` v1.0 ‚Üí v1.1** :
- Mapping MonetaryAmount/Duration ‚Üí ClientReference/PricingModel dans special_instructions

**Nouveaux scripts d'analyse** (`scripts/`) :
- `analyze_entities.py` : distribution types/relations d'une m√©moire
- `analyze_others.py` : d√©tail des "Other" par document source + patterns
- `fix_other_entities.py` : reclassification Cypher des "Other" existants

**Tests de r√©-ingestion : 4/4 = 0 Other** :
| Document | Other avant | Other apr√®s |
|---|---|---|
| presales/01_R√©f√©rences_client.md | 12 | **0** |
| docs/network/forti.md | 9 | **0** |
| docs/llmaas/llmaas.md | 11 | **0** |
| docs/iaas_bare-metal/quickstart.md | ~5 | **0** |

**Action** : r√©-ing√©rer enti√®rement DOCS avec `ingestdir` pour appliquer la nouvelle ontologie.

---

### Outil system_about + Starter Kit + Robustification client v1.3.5 (SESSION COURANTE ‚Äî 2026-02-18)

**Nouvel outil `system_about`** ‚Äî Carte d'identit√© compl√®te du service MCP Memory :
- Identit√©, capacit√©s (28 outils / 8 cat√©gories), 5 ontologies, formats support√©s
- M√©moires actives avec compteurs, √©tat des 5 services, configuration LLM/RAG
- Commande `about` dans CLI Click + shell interactif + affichage Rich (`show_about`)
- 28 outils MCP expos√©s (27 ‚Üí 28)

**Starter Kit d√©veloppeur** (`starter-kit/`) :
- Guide `README.md` : processus en 4 √©tapes pour ajouter un outil MCP
- Boilerplate fonctionnel dans `starter-kit/boilerplate/` (Docker, WAF, CLI, auth)

**Robustification `client.py`** :
- `call_tool()` g√®re `isError=True`, r√©ponse vide, r√©ponse non-JSON
- Plus de crash `json.loads` sur erreurs serveur ‚Üí messages exploitables

**Bug identifi√© et document√©** : `scripts/.env` charge `MCP_URL` pointant vers production via `load_dotenv()`. Le serveur de production n'a pas encore `system_about` ‚Üí "Unknown tool". Fonctionne sur localhost apr√®s `--url http://localhost:8080`. **Action** : red√©ployer en production.

---

### CLI ingestdir ‚Äî Progression temps r√©el + Fix --exclude v1.3.4 (SESSION COURANTE ‚Äî 2026-02-18)

**Alignement UX** : `ingestdir` (batch) utilise maintenant `run_ingest_with_progress()` pour chaque fichier, identique √† `ingest` (unitaire). Appliqu√© dans les deux interfaces (Shell interactif et CLI Click).

**Bug corrig√©** ‚Äî Parser `--exclude` cass√© dans le shell :
- L'ancien parser artisanal (recherche de sous-cha√Æne) avait 3 bugs : typos non d√©tect√©es (`--excluse` coll√© au chemin), guillemets non stripp√©s (`fnmatch` √©chouait), options inconnues silencieuses
- **Fix** : r√©√©criture avec `shlex.split()` (parsing POSIX) + it√©ration par tokens + d√©tection d'options inconnues
- CLI Click non affect√©e (Click g√®re nativement `@click.option("--exclude", multiple=True)`)

**Am√©liorations** :
- Progression temps r√©el par fichier : barres ASCII LLM/embedding, compteurs, timer
- Header enrichi : `[3/15] üì• bastion/concepts.md (12.4 KB)`
- R√©sum√© par fichier : `‚úÖ concepts.md: 12+3 entit√©s, 8+2 relations (45.2s)`
- Autocompl√©tion : `--exclude` et `--confirm` ajout√©s

**Fichiers modifi√©s** : `scripts/cli/shell.py`, `scripts/cli/commands.py`

---

### Ontologie cloud.yaml v1.1 (SESSION COURANTE ‚Äî 2026-02-18)

**Audit et am√©lioration** de l'ontologie `cloud.yaml` apr√®s confrontation avec le contenu r√©el de ~30 documents `DOCS/` et ~15 fiches `PRODUCT/`.

**Analyse** :
- Lecture de 12 documents √©chantillons (IaaS VMware, Block Storage, Managed K8s, Bastion, LLMaaS, Housing, IAM, SLA, Network)
- Comparaison avec les 4 autres ontologies (legal, technical, managed-services, presales)
- Audit du code `ontology.py` et `extractor.py` pour v√©rifier la compatibilit√© technique

**Modifications v1.0 ‚Üí v1.1** :
- **+4 entity types** : `PricingModel` (tarification omnipr√©sente dans PRODUCT), `StorageClass` (5 classes IOPS), `BackupSolution` (IBM SPP, VMware Replication), `AIModel` (LLMaaS)
- **+5 relation types** : `COMPATIBLE_WITH`, `SUPPORTS`, `PART_OF`, `DEPENDS_ON`, `HAS_PRICING` (14‚Üí19 relations, align√© avec les autres ontologies)
- **`priority: high`** ajout√© sur `CloudService` et `Technology` (en plus de `Certification` et `SLA`)
- **`priority_entities`** enrichi : +`StorageClass`, +`PricingModel`
- **Nettoyage `extraction_rules`** : suppression de 4 champs non reconnus par le code (`include_metrics`, `include_durations`, `include_amounts`, `extract_implicit_relations`)
- **+1 exemple d'extraction** bas√© fiche produit (Bastion, StorageClass, pricing, backup)
- **Contexte LLM enrichi** : consignes pour fiches produits (tarification, compatibilit√©s, mod√®les IA)
- **Exemples d'entit√©s enrichis** : ajout noms r√©els (PAR7S, TH3S, Cisco UCS B200, Intel Xeon Gold, Thales Luna, ISAE 3402, etc.)

**Script utilitaire** : `scripts/validate_ontology.py` cr√©√© puis supprim√© (utilitaire ponctuel, validation termin√©e).

**R√©sultat validation structurelle** : ‚úÖ 24 entity types, 19 relation types, 2 exemples, 0 erreur, 0 avertissement.

**Validation en conditions r√©elles (v1.3.3)** ‚Äî Ingestion de 2 fiches produits avec ontologie cloud v1.1 :
- IaaS VMware (13.6 KB) : **40 entit√©s, 52 relations, 0 "Other"** ‚Äî StorageClass:6, PricingModel:1, BackupSolution:1
- LLMaaS (19.5 KB) : **33 entit√©s, 36 relations, 2 "Other" (6%)** ‚Äî AIModel:6, PricingModel:4
- **Total : 73 entit√©s, 97.3% correctement typ√©es**, 18/24 types utilis√©s, 88 relations
- Les 2 "Other" sont des cas marginaux (pr√©avis contractuel + doublon SLA d√©j√† captur√©)

---

### Design Git-Sync (SESSION COURANTE ‚Äî 2026-02-18)

**Nouveau module con√ßu** : synchronisation automatique d'une m√©moire MCP avec un d√©p√¥t Git distant.

**Document de design** : `DESIGN/GIT_SYNC_DESIGN.md`

**Principe** :
1. Un script client autonome (`scripts/git_sync.py`) lanc√© par cron ou manuellement
2. Clone le repo si n√©cessaire, puis `git pull` √† chaque ex√©cution
3. Analyse le delta via `git diff --name-status <last_commit>..HEAD`
4. Applique les changements √† la m√©moire MCP :
   - **A (added)** ‚Üí `memory_ingest` (nouveau fichier)
   - **M (modified)** ‚Üí `memory_ingest(force=True)` (r√©-extraction compl√®te)
   - **D (deleted)** ‚Üí `document_delete` (suppression cascade Neo4j + Qdrant + S3)
   - **R (renamed)** ‚Üí delete ancien + ingest nouveau
5. Maintient un fichier d'√©tat `.git-sync-state.json` (dernier commit synchronis√©)

**D√©cisions prises** :
- Clone initial automatique si le repo n'existe pas localement
- Support `--subdir` pour synchroniser un sous-dossier vers une m√©moire sp√©cifique
- Pas de mapping multi-m√©moires (un repo = une m√©moire)
- Script client uniquement (pas d'outil MCP c√¥t√© serveur pour l'instant)
- Mapping fichier ‚Üî document via `source_path` (chemin relatif dans le repo)

**Modes** :
- **Incr√©mental** (d√©faut) : delta git depuis le dernier commit synchro
- **Full sync** (`--full-sync`) : r√©conciliation compl√®te fichiers locaux vs documents en m√©moire
- **Dry run** (`--dry-run`) : simulation sans modification

**Briques existantes r√©utilis√©es** :
- D√©duplication par hash SHA-256 (skip automatique des fichiers inchang√©s)
- `force=True` sur `memory_ingest` (supprime l'ancien + recr√©√©)
- `document_delete` (cascade: Neo4j + Qdrant + S3)
- `source_path` dans les m√©tadonn√©es du n≈ìud Document
- `MCPClient` de `scripts/cli/client.py` pour la communication HTTP/SSE

**Statut** : Design termin√©, pr√™t pour impl√©mentation future.

**Int√©gration CLI pr√©vue** :
- `document git-sync` (CLI Click)
- `git-sync` (shell interactif)
- Fonctions display dans `display.py`

---

### Int√©gration ontologie presales v1.2.5 ‚úÖ

**Nouvelle ontologie `presales.yaml`** ajout√©e dans `ONTOLOGIES/` pour les usages avant-vente et g√©n√©ration de propositions commerciales (RFP/RFI) Cloud Temple.

**Contenu de l'ontologie** :
- **28 types d'entit√©s** r√©partis en 6 familles : Acteurs & Personnes, S√©curit√© & Conformit√©, Technique & Infrastructure, Gouvernance & M√©thodologie, Commercial & Valeur, Contexte & Indicateurs
- **30 types de relations** r√©partis en 5 familles : Capacit√© & Conformit√©, Technique, Gouvernance, Commerciale, Structurelle & Contexte
- Entit√©s prioritaires : `Service`, `Certification`, `Differentiator`, `Requirement`, `SLA`, `ClientReference`
- Relations prioritaires : `HAS_CERTIFICATION`, `GUARANTEES`, `TARGETS_PERSONA`, `ANSWERED_BY`, `PART_OF_DOMAIN`, `PROVEN_BY`
- Limites adapt√©es : `max_entities: 60`, `max_relations: 80` (ontologie plus riche que les autres)

**Correction YAML** : le fichier d'origine contenait des patterns YAML invalides (`- "Texte" (annotation)`) corrig√©s en `- "Texte (annotation)"` sur 8 blocs (Organization, Person, Persona, Methodology, Technology, KPI, PresalesDomain).

**D√©fauts Python relev√©s √† 60/80** (`src/mcp_memory/core/ontology.py`) :
- Dataclass `ExtractionRules` : `max_entities: int = 60`, `max_relations: int = 80`
- Loader `_load_ontology_file` : `rules_data.get('max_entities', 60)`, `rules_data.get('max_relations', 80)`
- Impact : toutes les ontologies sans valeur explicite (legal, cloud, technical, managed-services) b√©n√©ficient maintenant des limites 60/80. `presales.yaml` conserve ses valeurs explicites identiques.

**D√©ploy√© en local** : rebuild + red√©marrage. V√©rification : `python3 scripts/mcp_cli.py ontologies` ‚Üí 5 ontologies disponibles.

**‚ö†Ô∏è Production** : sur le serveur `prod-docker02`, faire `git pull && docker compose build mcp-memory && docker compose up -d mcp-memory`.

---

### Factorisation CLI Click / Shell interactif v1.2.4 ‚úÖ (SESSION COURANTE)

Le code dupliqu√© entre `commands.py` (CLI Click) et `shell.py` (shell interactif) a √©t√© factoris√© :

**Nouveau module `scripts/cli/ingest_progress.py`** :
- `create_progress_state()`, `make_progress_bar()`, `create_progress_callback()`, `run_ingest_with_progress()`
- Toute la m√©canique Rich Live + parsing SSE en un seul endroit

**Fonctions partag√©es ajout√©es dans `display.py`** :
- `format_size()` publique (3 copies ‚Üí 1)
- `show_ingest_preflight()`, `show_entities_by_type()`, `show_relations_by_type()`

**R√©sultat** : ~300 lignes de duplication supprim√©es, 0 changement fonctionnel.
Architecture CLI : `__init__.py` ‚Üí `client.py` ‚Üí `display.py` ‚Üí `ingest_progress.py` ‚Üí `commands.py` / `shell.py`

### Alignement Shell interactif ‚Äî Progression ingestion temps r√©el v1.2.3 ‚úÖ

**Probl√®me** : La commande `ingest` dans le shell interactif (`shell.py`) n'affichait qu'un simple spinner pendant l'ingestion, alors que la commande Click (`commands.py`) affichait une progression riche en temps r√©el avec barres ASCII, compteurs d'entit√©s/relations et phases d√©taill√©es.

**√âcart constat√©** :
| Fonctionnalit√© | CLI Click (`commands.py`) | Shell (`shell.py`) avant |
|---|---|---|
| Callback `on_progress` | ‚úÖ Parse notifications serveur | ‚ùå Non utilis√© |
| Barres ASCII `‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë‚ñë` | ‚úÖ Extraction LLM + Embedding | ‚ùå Absent |
| Phases d√©taill√©es | ‚úÖ S3‚Üítexte‚ÜíLLM‚ÜíNeo4j‚Üíchunking‚Üíembedding‚ÜíQdrant | ‚ùå Spinner unique |
| Compteurs temps r√©el | ‚úÖ Entit√©s/Relations pendant extraction | ‚ùå Absent |
| Rich Live display | ‚úÖ 4 rafra√Æchissements/seconde | ‚ùå Non |

**Correction** : Copie du m√©canisme complet de progression dans `cmd_ingest` du shell :
- `_progress_state` dict pour tracker les phases et compteurs
- `_on_progress()` async callback qui parse les messages serveur via regex
- `_make_bar()` pour les barres ASCII avec pourcentage
- `_update_display()` coroutine avec `Rich Live` (refresh 4x/s)
- Passage de `on_progress=_on_progress` √† `client.call_tool()`

**R√©sultat** : Le shell interactif affiche maintenant la m√™me progression temps r√©el que la CLI Click pour l'ingestion de documents.

### Fix HTTP 421 ‚Äî HostNormalizerMiddleware pour reverse proxy v1.2.2 ‚úÖ

**Probl√®me** : Les clients MCP (Cline, CLI, agents IA) ne pouvaient pas se connecter au serveur de production via SSE. Les endpoints `/sse` et `/messages/*` retournaient **HTTP 421 "Invalid Host header"**.

**Cause racine** :
- Le reverse proxy (nginx ‚Üí Caddy ‚Üí MCP) transmet le `Host` header public (`graph-mem.mcp.cloud-temple.app`)
- Le MCP SDK (Starlette) valide le Host header et rejette toute valeur autre que `localhost:8002`
- Les routes `/api/*` fonctionnaient car intercept√©es par `StaticFilesMiddleware` (notre code) avant d'atteindre Starlette
- Seules les routes `/sse` et `/messages/*` (g√©r√©es par `mcp.sse_app()` = Starlette) √©taient affect√©es

**Correction (double fix)** :
1. **Fix principal** : `FastMCP(host=settings.mcp_server_host)` ‚Üí `host="0.0.0.0"` d√©sactive la protection DNS rebinding du SDK MCP v1.26+ (`TransportSecurityMiddleware`). Le SDK ne v√©rifie le Host header QUE si `host` est dans `("127.0.0.1", "localhost", "::1")`.
   - Ref: `mcp/server/fastmcp/server.py` ligne 166 + `mcp/server/transport_security.py`
2. **Ceinture de s√©curit√©** : `HostNormalizerMiddleware` ASGI entre `StaticFilesMiddleware` et `mcp.sse_app()` ‚Äî normalise le Host header vers `localhost` comme protection suppl√©mentaire.

**Pile de middlewares (ordre d'ex√©cution)** :
```
AuthMiddleware ‚Üí LoggingMiddleware ‚Üí StaticFilesMiddleware ‚Üí HostNormalizerMiddleware ‚Üí mcp.sse_app()
```

**Am√©lioration client** :
- Nouvelle m√©thode `_extract_root_cause()` dans `scripts/cli/client.py`
- Descend r√©cursivement dans les `ExceptionGroup`/`TaskGroup` pour extraire le vrai message d'erreur
- Suggestion de diagnostic si erreur Host d√©tect√©e

**‚ö†Ô∏è Action requise** : Rebuild Docker sur le serveur Cloud Temple (`git pull && docker compose build mcp-memory && docker compose up -d mcp-memory`)

### Fix CLI production ‚Äî Variables MCP_URL / MCP_TOKEN v1.2.1 ‚úÖ

**Probl√®me** : Le CLI (`mcp_cli.py`) ne pouvait pas se connecter au serveur de production d√©ploy√© sur `https://graph-mem.mcp.cloud-temple.app`.

**Cause racine** (double conflit de variables d'environnement) :
1. `scripts/cli/__init__.py` lisait `MCP_SERVER_URL` (pas `MCP_URL`) comme variable d'env
2. `scripts/cli/commands.py` : les options Click d√©claraient `envvar="ADMIN_BOOTSTRAP_KEY"` ‚Üí `load_dotenv()` chargeait le `.env` local dev (`ADMIN_BOOTSTRAP_KEY=admin_bootstrap_key_change_me`) qui **√©crasait** le default calcul√© depuis `MCP_TOKEN`

**Corrections** :
- `__init__.py` : `MCP_URL` et `MCP_TOKEN` prioritaires (fallback `MCP_SERVER_URL` / `ADMIN_BOOTSTRAP_KEY`)
- `commands.py` : Click `envvar=["MCP_URL", "MCP_SERVER_URL"]` et `["MCP_TOKEN", "ADMIN_BOOTSTRAP_KEY"]` ‚Äî premi√®re trouv√©e gagne
- Documentation compl√®te : `scripts/README.md`, `DESIGN/DEPLOIEMENT_PRODUCTION.md` ¬ß15, `.env.example`

**R√®gle** : `.env` = config **serveur** (S3, Neo4j, etc.) / `MCP_URL` + `MCP_TOKEN` = config **client CLI** (pas dans le .env)

### D√©ploiement production v1.2.0 ‚úÖ

- Serveur d√©ploy√© sur `prod-docker02` (192.168.10.21)
- URL : `https://graph-mem.mcp.cloud-temple.app`
- TLS g√©r√© par reverse proxy nginx en amont (pas par Caddy)
- WAF en mode HTTP `:8080` (`SITE_ADDRESS=:8080`)
- Guide complet : `DESIGN/DEPLOIEMENT_PRODUCTION.md`

### Backup / Restore complet v1.2.0 ‚úÖ

**Syst√®me de backup/restore** impl√©ment√© et test√© pour les 3 couches de donn√©es :
- **Neo4j** (graphe : Memory, Documents, Entit√©s, Relations, Mentions)
- **Qdrant** (vecteurs RAG : chunks embeddings avec payloads)
- **S3** (documents originaux : v√©rification d'existence + re-upload depuis archive)

**Architecture** :
- `core/backup.py` ‚Äî `BackupService` : orchestrateur backup/restore/list/download/delete/restore_from_archive
- Stockage des backups sur S3 : `_backups/{memory_id}/{timestamp}/` (graph_data.json + qdrant_vectors.jsonl + manifest.json + document_keys.json)
- `graph.py` : `export_full_graph()` / `import_full_graph()` (Cypher MERGE idempotent)
- `vector_store.py` : `export_all_vectors()` / `import_vectors()` (scroll Qdrant complet)
- Config : `BACKUP_RETENTION_COUNT=5` (rotation automatique)

**7 outils MCP** ajout√©s dans `server.py` :
1. `backup_create` ‚Äî Backup complet (graphe + vecteurs + manifest + document_keys)
2. `backup_list` ‚Äî Liste les backups (optionnel: par memory_id)
3. `backup_restore` ‚Äî Restaure graphe + vecteurs depuis backup S3 (m√©moire ne doit pas exister)
4. `backup_download` ‚Äî Archive tar.gz en base64 (optionnel: `include_documents` pour inclure les PDFs/DOCX)
5. `backup_delete` ‚Äî Supprime un backup de S3
6. `backup_restore_archive` ‚Äî **Restaure depuis une archive tar.gz locale** (base64) :
   - Extrait le tar.gz en m√©moire
   - V√©rifie les checksums SHA-256 des documents inclus
   - Re-uploade les documents sur S3 avec leurs cl√©s originales
   - Restaure le graphe Neo4j + vecteurs Qdrant

**Cycle complet valid√©** :
1. ‚úÖ Create m√©moire + ingest document ‚Üí 8 entit√©s, 10 relations, 4 vecteurs
2. ‚úÖ Backup + download tar.gz avec `--include-documents` ‚Üí 23.2 KB (contient `documents/test-doc-backup.md`)
3. ‚úÖ Suppression TOTALE (m√©moire + backup S3 = plus rien c√¥t√© serveur)
4. ‚úÖ **Restore depuis fichier tar.gz local** en 0.3s ‚Üí graphe + vecteurs + document S3 tous restaur√©s
5. ‚úÖ V√©rification `storage check` : 1/1 docs accessibles sur S3, 8 entit√©s intactes

**CLI compl√®te** (3 couches align√©es) :
- Click : `backup create/list/restore/download/delete/restore-file`
- Shell : commandes correspondantes dans shell interactif
- Display : `show_backup_result()`, `show_backups_table()`, `show_restore_result()`

### Fix storage_check v1.2.0 ‚úÖ

Deux bugs corrig√©s dans `storage_check` (server.py) :
1. **Exclusion `_backups/`** ‚Äî Les fichiers du pr√©fixe `_backups/` √©taient signal√©s comme orphelins. Ajout d'un filtre au m√™me titre que `_health_check/` et `_ontology_`.
2. **Scope multi-m√©moires pour orphelins** ‚Äî Quand scop√© √† une m√©moire (`storage check JURIDIQUE`), les orphelins √©taient calcul√©s en ne consid√©rant que les docs de cette m√©moire, donc les 38 docs des autres m√©moires apparaissaient comme faux-positifs. Maintenant, la d√©tection d'orphelins charge TOUTES les m√©moires m√™me quand scop√©.

R√©sultat : `storage check JURIDIQUE` passe de 42 faux orphelins √† **1 seul vrai orphelin** (177 KB).

### S√©curit√© WAF v1.1.0 ‚Äî Rate Limiting + Analyse de Risques

**Rate Limiting** impl√©ment√© et test√© ‚úÖ :
- Module `caddy-ratelimit` compil√© dans l'image WAF (`waf/Dockerfile` via `xcaddy`)
- 4 zones par IP dans `waf/Caddyfile` : SSE 10/min, messages 60/min, API 30/min, global 200/min
- Test√© : 30 requ√™tes passent, 31e ‚Üí HTTP 429 (exact)
- Script de test : `scripts/test_rate_limit.sh`

**Analyse de Risques S√©curit√©** cr√©√©e (`DESIGN/ANALYSE_RISQUES_SECURITE.md`) :
- Matrice compl√®te par route (/sse, /messages, /api, /public)
- Conformit√© OWASP Top 10, SecNumCloud, RGPD

### Infrastructure s√©curis√©e (v0.6.6 ‚Üí v1.0.0)

- **Coraza WAF** : reverse proxy OWASP CRS, seul port 8080 expos√©
- **TLS Let's Encrypt natif** : `SITE_ADDRESS` pour basculer dev/prod
- **Container non-root** : `USER mcp`
- **R√©seau Docker isol√©** : Neo4j/Qdrant internes uniquement

## R√®gle d'alignement ‚Äî TOUJOURS RESPECTER

```
API MCP ‚Üí CLI Click (commands.py) ‚Üí Shell interactif (shell.py)
```

**Toute nouvelle fonctionnalit√© doit √™tre ajout√©e dans les TROIS couches.**

## D√©cisions architecturales
- **28 outils MCP** expos√©s via HTTP/SSE (v1.3.5)
- Client web modulaire : 8 fichiers < 210 lignes
- CLI Click = interface scriptable, Shell = interface interactive
- M√™me affichage Rich (fonctions display.py partag√©es)
- Couplage strict : Neo4j + Qdrant obligatoires
- Extraction graph : s√©quentielle avec contexte cumulatif (pas de parall√©lisme)
- Chunks d'extraction : ~25K chars (~6K tokens)
- Notifications MCP : `ctx.info()` c√¥t√© serveur ‚Üí `_received_notification` c√¥t√© client
- Backups stock√©s sur S3 (m√™me bucket, pr√©fixe `_backups/`)
- Restore depuis archive : re-upload docs S3 + checksum SHA-256

### Durcissement s√©curit√© backup v1.2.0 ‚úÖ (SESSION COURANTE)

**5 failles corrig√©es** dans le syst√®me de backup :

1. **üî¥ Path traversal dans `restore_from_archive`** ‚Äî Un nom de fichier malveillant dans l'archive (`../../etc/passwd`) pouvait √™tre inject√©. Ajout de :
   - Rejet des noms contenant `..` ou commen√ßant par `/`
   - Normalisation via `os.path.basename()`
   - Log des rejets et normalisations dans stderr

2. **üî¥ Injection dans `backup_id`** ‚Äî Le `backup_id` (format `memory_id/timestamp`) √©tait utilis√© sans validation pour construire des cl√©s S3. Ajout de `_validate_backup_id()` :
   - Regex `^[A-Za-z0-9_-]+$` sur chaque composant
   - Bloque `../secrets/config` et similaires
   - Appliqu√© dans `restore_backup`, `download_backup`, `delete_backup`

3. **üü° Contr√¥le permission `write`** ‚Äî Les outils backup destructeurs n'exigeaient aucune permission sp√©cifique. Ajout de `check_write_permission()` dans `auth/context.py` :
   - V√©rifie que le token a la permission `write` ou `admin`
   - Appliqu√© √† `backup_create`, `backup_restore`, `backup_delete`, `backup_restore_archive`
   - Token read-only ne peut plus modifier les backups

4. **üü° Cross-memory access control** ‚Äî Un token autoris√© pour JURIDIQUE pouvait acc√©der aux backups de CLOUD. Maintenant :
   - `backup_restore/download/delete` extraient le `memory_id` du `backup_id` via `_validate_backup_id()`
   - Appel `check_memory_access(memory_id)` AVANT l'op√©ration

5. **üü° Limite taille archive** ‚Äî `restore_from_archive` acceptait des archives de taille illimit√©e (DoS). Ajout de :
   - `MAX_ARCHIVE_SIZE_BYTES = 100 MB`
   - Rejet imm√©diat avant extraction tar.gz

**Fichiers modifi√©s** : `core/backup.py`, `auth/context.py`, `server.py`

### Fix UX CLI v1.2.0 ‚úÖ

- **Backup ID non tronqu√©** : colonne `no_wrap=True` + `min_width=35` dans `show_backups_table()` (display.py)
- **Date non tronqu√©e** : colonne `no_wrap=True` + `min_width=19`
- **`backup-download --include-documents`** : option ajout√©e dans le shell (d√©tection, passage √† l'API, aide contextuelle)
- **Autocompl√©tion** : `--include-documents` et `--force` ajout√©s √† `SHELL_COMMANDS`
- **Table d'aide** : backup-download mentionne `--include-documents`
- **README CLI** (`scripts/README.md`) : section Backup/Restore compl√®te ajout√©e (Click + Shell), option `--include-documents` document√©e
- **README principal** : noms de commandes shell corrig√©s (`backup-create` au lieu de `backup create`)

## Prochaines √©tapes
- [ ] Ing√©rer plus de documents juridiques (CGVU, Contrat Cadre, Convention de Services)
- [ ] Am√©liorer la d√©tection de sections DOCX (tables converties en texte plat)
- [ ] Export du graphe (JSON-LD, RDF, Cypher)
- [ ] Dashboard de monitoring
- [ ] Comparer CGA/CGV (outil de diff s√©mantique)
- [ ] Backup/restore via interface web (pas seulement CLI)
