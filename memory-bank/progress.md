# Progress

## Ce qui fonctionne ‚úÖ

### Infrastructure
- Serveur MCP via HTTP/SSE (FastMCP + uvicorn)
- Docker Compose (WAF + MCP + Neo4j + Qdrant)
- **Coraza WAF** (v0.6.6) : reverse proxy OWASP CRS, seul port 8080 expos√©
- **Rate Limiting** (v1.1.0) : `caddy-ratelimit` 4 zones par IP (SSE 10/min, messages 60/min, API 30/min, global 200/min). Test√© : HTTP 429 au-del√† des limites.
- **Analyse de Risques** (v1.1.0) : `DESIGN/ANALYSE_RISQUES_SECURITE.md` ‚Äî matrice par route, vecteurs d'attaque, conformit√© OWASP/SecNumCloud/RGPD
- **TLS Let's Encrypt** (v0.6.6) : `SITE_ADDRESS` pour basculer dev/prod
- **Dockerfile non-root** (v0.6.6) : `USER mcp`, plus de container root
- **R√©seau Docker isol√©** (v0.6.6) : Neo4j/Qdrant internes uniquement
- Authentification Bearer Token + Bootstrap Admin Key
- Auth middleware : localhost (127.0.0.1) exempt d'authentification
- Stockage S3 Dell ECS (upload/download documents)
- `EXTRACTION_MAX_TEXT_LENGTH` refactoris√© en garde-fou (v0.6.6) : rejette explicitement au lieu de tronquer

### Outil system_about + Starter Kit (v1.3.5)
- **`system_about`** : carte d'identit√© compl√®te du service (identit√©, 28 outils/8 cat√©gories, 5 ontologies, m√©moires actives, √©tat services, configuration LLM/RAG)
- Commande `about` dans CLI Click + shell interactif + affichage Rich `show_about()`
- **Starter Kit** (`starter-kit/`) : guide 4 √©tapes + boilerplate fonctionnel (Docker, WAF, CLI, auth)
- **`client.py` robustifi√©** : gestion `isError`, r√©ponse vide, r√©ponse non-JSON (plus de crash `json.loads`)

### CLI refactoris√©e et align√©e (package `scripts/cli/`)
- 7 fichiers, tous < 500 lignes, bien comment√©s
- `client.py` ‚Äî MCPClient REST + SSE
- `display.py` ‚Äî Affichage Rich partag√© (tables, panels, graphe, entit√©s, Q&A, `format_size`, `show_ingest_preflight`, `show_entities_by_type`, `show_relations_by_type`)
- `ingest_progress.py` ‚Äî Progression ingestion temps r√©el partag√©e (`create_progress_state`, `make_progress_bar`, `create_progress_callback`, `run_ingest_with_progress`)
- `commands.py` ‚Äî Commandes Click (health, memory, document, storage, ask, ontologies)
- `shell.py` ‚Äî Shell interactif prompt_toolkit (22 commandes)
- Point d'entr√©e : `python3 scripts/mcp_cli.py`
- **R√®gle d'alignement** : API MCP ‚Üí CLI Click ‚Üí Shell (toujours les 3 couches)
- **Factorisation v1.2.4** : ~300 lignes de duplication supprim√©es (entities, relations, ingest progress, format_size) ‚Äî 0 changement fonctionnel
- **Variables CLI v1.2.1** : `MCP_URL` + `MCP_TOKEN` prioritaires sur `MCP_SERVER_URL` + `ADMIN_BOOTSTRAP_KEY` (√©vite conflit dev/prod avec `load_dotenv()`)

### Shell interactif
- Autocompl√©tion Tab (prompt_toolkit)
- Historique persistant ‚Üë‚Üì (~/.mcp_memory_history)
- √âdition avanc√©e (Ctrl+A/E/W)
- Commandes : list, use, info, graph, docs, entities, entity, relations, ask, query, limit, delete, debug, clear, exit
- **Option `--json` globale** (v0.6.5) : utilisable sur toute commande de consultation (list, info, graph, docs, entities, entity, relations, ask, query). Affiche le JSON brut sans formatage Rich. D√©tection automatique n'importe o√π dans la ligne.
- `use` valide le memory_id, extrait l'ID si copi√© avec le nom
- `relations <TYPE>` deepdive par type
- `entities` avec colonne Document(s) source
- `limit [N]` configurable par session (pass√© √† l'API)
- **Progression ingestion temps r√©el** (v1.2.3) : `cmd_ingest` utilise Rich Live + callback `on_progress` pour afficher barres ASCII extraction LLM/embedding, compteurs entit√©s/relations, phases S3‚Üítexte‚ÜíLLM‚ÜíNeo4j‚Üíchunking‚Üíembedding‚ÜíQdrant ‚Äî m√™me affichage que la CLI Click
- **Progression temps r√©el pour ingestdir** (v1.3.4) : `cmd_ingestdir` et `document_ingest_dir` utilisent `run_ingest_with_progress()` pour chaque fichier (m√™me UX que `ingest` unitaire). Header `[X/N] üì• fichier (taille)`, barres LLM/embedding, r√©sum√© `new+merged entit√©s/relations (dur√©e)`.
- **Parser --exclude robuste** (v1.3.4) : `shlex.split()` dans le shell (g√®re guillemets, options inconnues d√©tect√©es avec message d'erreur clair). CLI Click non affect√©e (Click g√®re nativement `multiple=True`).

### Gestion des m√©moires
- Cr√©ation avec ontologie obligatoire (copi√©e sur S3)
- Suppression (cascade : docs + entit√©s + relations)
- Listing et statistiques
- Graphe complet (API REST + outil MCP)

### Ingestion de documents
- Formats : txt, md, html, docx, pdf, csv
- D√©duplication par hash SHA-256
- Force re-ingestion : supprime l'ancien document + entit√©s orphelines avant recr√©ation
- Extraction LLM guid√©e par ontologie
- R√©ponse enrichie : entities/relations created/merged, types
- `--force` disponible en CLI

### Extraction (am√©lior√©e)
- Extraction guid√©e par ontologie
- `EXTRACTION_MAX_TEXT_LENGTH` configurable (fin du hardcod√© 50K)
- `generate_answer` utilise `self._max_tokens` (plus de limite 1000)
- Ontologie legal.yaml : instruction exhaustivit√© des articles
- Instructions anti-hub dans le prompt
- 0 RELATED_TO sur corpus juridique (relations s√©mantiques sp√©cifiques)

### Recherche et Q&A
- Recherche d'entit√©s par texte (limit configurable)
- Contexte d'entit√© (voisins + documents)
- Question/R√©ponse via LLM avec contexte du graphe
- Documents sources affich√©s dans les r√©ponses
- `limit` comme param√®tre API optionnel
- **`memory_query`** (v0.6.5) ‚Äî Interrogation structur√©e sans LLM. M√™me pipeline que `question_answer` (graphe + RAG) mais retourne donn√©es brutes : entit√©s enrichies (relations, voisins, docs), chunks RAG avec scores, statistiques. Id√©al pour agents IA.

### Ontologies
- 5 ontologies : legal, cloud, managed-services, technical, **presales** (v1.3.0)
- legal.yaml : 22 types entit√©s, 22 types relations, instructions exhaustivit√©
- presales.yaml : 28 types entit√©s (6 familles), 30 types relations (5 familles), max_entities=60, max_relations=80
  - Familles entit√©s : Acteurs & Personnes, S√©curit√© & Conformit√©, Technique & Infrastructure, Gouvernance & M√©thodologie, Commercial & Valeur, Contexte & Indicateurs
  - Entit√©s prioritaires : Service, Certification, Differentiator, Requirement, SLA, ClientReference
  - Relations prioritaires : HAS_CERTIFICATION, GUARANTEES, TARGETS_PERSONA, ANSWERED_BY, PART_OF_DOMAIN, PROVEN_BY
- general.yaml **v1.1** : 28 types entit√©s (5 familles), 24 types relations (6 familles), max_entities=60, max_relations=80
  - v1.0‚Üív1.1 : +4 entit√©s (LegalProvision, Sector, Sanction, Stakeholder), +2 relations (APPLIES_TO, IMPOSES)
  - ~50 lignes `special_instructions` additionnelles (textes r√©glementaires, RSE/mat√©rialit√©, 15 mappings anti-"Other")
  - Couverture des 299 "Other" de REFERENTIEL : articles de loi, secteurs NIS2/DORA, stakeholders RSE, sanctions, deadlines, r√©solutions AG, rapports, zones PAMS, qualifications ANSSI
  - **En attente r√©-ingestion** des 7 documents probl√©matiques (NIS2, DORA, NEURONES, PAMS, SecNumCloud, HDS, DiagCarbone)
- cloud.yaml **v1.2** : 27 types entit√©s, 19 types relations, max_entities=60, max_relations=80
  - v1.0‚Üív1.1 : +4 entit√©s (PricingModel, StorageClass, BackupSolution, AIModel), +5 relations
  - **v1.1‚Üív1.2** : +2 entit√©s (`Role` IAM/RBAC, `SLALevel` P1-P5/Impact/Criticit√©), +50 lignes `special_instructions`
  - 12 mappings obligatoires (Endpoint‚ÜíAPI, Licence‚ÜíPricingModel, HA‚ÜíTechnology, Feature‚ÜíNetworkComponent, etc.)
  - 8 cat√©gories d'exclusion (CLI flags, variables, erreurs, param√®tres API, titres de sections)
  - R√®gle de qualit√© des noms descriptifs
  - **Tests r√©-ingestion 4/4 = 0 "Other"** (forti.md, llmaas.md, quickstart.md, R√©f√©rences_client.md)
- presales.yaml **v1.1** : mapping MonetaryAmount/Duration ‚Üí ClientReference/PricingModel
  - Test r√©-ingestion 01_R√©f√©rences_client.md : 12 Other ‚Üí **0 Other**

### Scripts d'analyse ontologie (v1.3.6)
- `scripts/analyze_entities.py` : distribution types entit√©s/relations d'une m√©moire (top N + d√©tail "Other")
- `scripts/analyze_others.py` : d√©tail des entit√©s "Other" par document source + cat√©gorisation
- `scripts/fix_other_entities.py` : reclassification Cypher des "Other" existants (dry-run + --apply)

### V√©rification et nettoyage S3
- `storage_check(memory_id?)` ‚Äî V√©rifie coh√©rence graphe ‚Üî S3 (accessibilit√©, orphelins)
- `storage_cleanup(dry_run=True)` ‚Äî Nettoie les fichiers orphelins S3
- `document_delete` supprime maintenant le fichier S3 associ√©
- `memory_delete` supprime tous les fichiers S3 du pr√©fixe m√©moire
- CLI : commandes `check` et `cleanup` (+ `cleanup --force`)
- Affichage Rich : panneau r√©sum√©, tableau docs/orphelins, tailles

### Gestion des tokens et contr√¥le d'acc√®s m√©moire (session 02/09/2026 apr√®s-midi)
- `admin_update_token` ‚Äî Nouvel outil MCP pour modifier les memory_ids d'un token (add/remove/set)
- `auth/context.py` ‚Äî `contextvars.ContextVar` pour propager l'auth du middleware aux outils MCP
- `check_memory_access()` ‚Äî V√©rification d'acc√®s dans chaque outil m√©moire (memory_create, _delete, _ingest, _search, question_answer, etc.)
- CLI Click : groupe `token` avec 6 sous-commandes (list, create, revoke, grant, ungrant, set-memories)
- Shell interactif : 6 nouvelles commandes (tokens, token-create, token-revoke, token-grant, token-ungrant, token-set)
- `display.py` : `show_tokens_table()`, `show_token_created()`, `show_token_updated()`
- Middleware injecte `current_auth.set()` pour bootstrap et tokens clients

### RAG Vectoriel Graph-Guided (session 02/09/2026 apr√®s-midi ‚Äî 2e partie)
- **Qdrant** : base vectorielle (docker-compose, healthcheck, volume persistant)
- **Couplage strict** : Neo4j + Qdrant obligatoires (pas de mode d√©grad√©)
- **SemanticChunker** (`core/chunker.py`) :
  - 3 passes : DETECT structure ‚Üí SPLIT phrases ‚Üí MERGE chunks avec overlap
  - D√©tecte articles num√©rot√©s, headers Markdown, num√©rotation hi√©rarchique, titres majuscules
  - Ne coupe jamais au milieu d'une phrase
  - Overlap au niveau des phrases (configurable)
  - Pr√©fixe contextuel [Article X - Titre] sur chaque chunk
- **EmbeddingService** (`core/embedder.py`) : LLMaaS bge-m3:567m, 1024 dimensions, batch
- **VectorStoreService** (`core/vector_store.py`) : CRUD Qdrant, search filtr√© par doc_ids
- **Ingestion** : Graph + Chunk + Embed + Qdrant (synchrone strict, rollback si erreur)
- **Q&A Graph-Guided RAG** : graphe identifie doc_ids ‚Üí Qdrant filtre chunks ‚Üí double contexte LLM
- **Suppressions** : document_delete et memory_delete suppriment aussi dans Qdrant (strict)
- **system_health** : teste 5 services (S3, Neo4j, LLMaaS, Qdrant, Embedding)
- **Mod√®les** : Chunk + ChunkResult dans models.py

### Backup / Restore complet (v1.2.0)
- **BackupService** (`core/backup.py`) ‚Äî Orchestrateur backup/restore/list/download/delete/restore_from_archive
- **3 couches sauvegard√©es** : Neo4j (graphe complet), Qdrant (vecteurs RAG), S3 (documents originaux)
- Stockage backups sur S3 : `_backups/{memory_id}/{timestamp}/` (graph_data.json + qdrant_vectors.jsonl + manifest.json + document_keys.json)
- `graph.py` : `export_full_graph()` (labels dynamiques) / `import_full_graph()` (MERGE idempotent)
- `vector_store.py` : `export_all_vectors()` (scroll complet) / `import_vectors()` (upsert batch)
- Config : `BACKUP_RETENTION_COUNT=5` (rotation automatique, supprime les plus anciens)
- **7 outils MCP** : `backup_create`, `backup_list`, `backup_restore`, `backup_download`, `backup_delete`, `backup_restore_archive`
- **`backup_restore_archive`** : restaure depuis un fichier tar.gz local (base64). Re-uploade les documents S3 inclus dans l'archive + restaure graphe Neo4j + vecteurs Qdrant. V√©rifie checksums SHA-256.
- **CLI Click** : groupe `backup` avec 6 sous-commandes (create/list/restore/download/delete/restore-file)
- **Shell interactif** : commandes backup correspondantes
- **Display Rich** : `show_backup_result()`, `show_backups_table()`, `show_restore_result()`
- Restore v√©rifie que la m√©moire n'existe pas (√©vite √©crasement accidentel)
- Download g√©n√®re une archive tar.gz (optionnel: `--include-documents` pour inclure les PDFs/DOCX originaux)
- **Cycle complet valid√©** : create ‚Üí ingest ‚Üí backup ‚Üí download tar.gz ‚Üí delete tout ‚Üí restore depuis fichier local ‚Üí verify OK (0.3s)

### Durcissement s√©curit√© backup (v1.2.0)
- **`_validate_backup_id()`** : regex `^[A-Za-z0-9_-]+$` sur chaque composant du backup_id (anti path-traversal S3)
- **Path traversal `restore_from_archive`** : rejet `..` et `/`, normalisation `os.path.basename()`, log des rejets
- **`check_write_permission()`** : nouvelle fonction dans `auth/context.py`, v√©rifie permission `write` ou `admin`
- **Contr√¥le write** appliqu√© √† : `backup_create`, `backup_restore`, `backup_delete`, `backup_restore_archive`
- **Cross-memory access control** : `backup_restore/download/delete` extraient `memory_id` du `backup_id` et appellent `check_memory_access()` AVANT l'op√©ration
- **Limite taille archive** : `MAX_ARCHIVE_SIZE_BYTES = 100 MB`, rejet imm√©diat avant extraction tar.gz (anti DoS)

### Fix storage_check (v1.2.0)
- Les fichiers `_backups/` sont exclus de la d√©tection d'orphelins (g√©r√©s par `backup_list`)
- Quand scop√© √† une m√©moire, la d√©tection d'orphelins charge les URIs de TOUTES les m√©moires (pas de faux-positifs)

### Int√©gration Live Memory (2026-02-21)
- **Architecture m√©moire √† deux niveaux** document√©e dans le README : Live Memory (m√©moire de travail) ‚Üî Graph Memory (m√©moire long terme)
- 4 outils MCP dans Live Memory pour l'int√©gration : `graph_connect`, `graph_push`, `graph_status`, `graph_disconnect`
- Flux : `bank_consolidate` ‚Üí `graph_push` (delete + re-ingest ‚Üí recalcul du graphe)
- Les fichiers Markdown de la memory bank Live Memory deviennent des entit√©s et relations interrogeables en langage naturel
- R√©f√©rence acad√©mique : Tran et al., 2025 ‚Äî *Multi-Agent Collaboration Mechanisms*

### Branding & Q&A am√©lior√©
- Logo Cloud Temple SVG en header + couleur accent `#41a890`
- Prompt ASK cite les documents sources (chaque entit√© inclut `[Source: filename]`)
- API REST `/api/ask` d√©l√®gue √† `question_answer()` (DRY, source unique de v√©rit√©)

### Client web modulaire (8 fichiers)
- Architecture : graph.html + css/graph.css + 6 fichiers JS
- vis-network pour le graphe (force-directed, zoom, drag, s√©lection)
- **Filtrage avanc√© (3 panneaux pliables)** :
  - Types d'entit√©s : checkboxes avec pastilles couleur, compteurs, Tous/Aucun/Inverser
  - Types de relations : checkboxes avec barres couleur, compteurs, Tous/Aucun/Inverser
  - Documents : checkboxes individuelles, masquage cascade entit√©s exclusives
- **Mode Focus Question (ASK)** :
  - Bouton "üî¨ Isoler le sujet" apr√®s chaque r√©ponse
  - Isole le sous-graphe : entit√©s r√©ponse + voisins 1 hop + ar√™tes entre eux
  - Banni√®re "Mode Focus" avec bouton "üîÑ Graphe complet" pour restaurer
- Panneau d√©tails n≈ìud (relations, documents, description)
- ASK int√©gr√© : question en langage naturel ‚Üí r√©ponse LLM + highlight entit√©s
- Entit√©s cliquables dans la r√©ponse ‚Üí focus sur le n≈ìud dans le graphe
- Rendu Markdown complet (marked.js CDN) : tableaux, listes, code, blockquotes
- Modale param√®tres (distance, r√©pulsion, taille n≈ìuds/texte)
- Recherche locale d'entit√©s dans la sidebar
- √âtat de filtrage centralis√© (`filterState` dans config.js, `applyFilters()`)
- API REST : GET /api/memories, GET /api/graph/{id}, POST /api/ask

### M√©tadonn√©es enrichies sur les documents (v0.6.0)
- N≈ìud Document enrichi dans Neo4j : `source_path`, `source_modified_at`, `size_bytes`, `text_length`, `content_type`
- `source_path` et `source_modified_at` pass√©s optionnellement par le client √† l'ingestion
- `size_bytes`, `text_length`, `content_type` calcul√©s automatiquement c√¥t√© serveur
- `get_document()` et `get_full_graph()` retournent les m√©tadonn√©es enrichies
- Permet la d√©tection de modifications (hash ‚â†, taille ‚â†, date source plus r√©cente)
- **CLI enrichi** : `document ingest` (+ `--source-path`), `document ingest-dir`, `cmd_ingest`, `cmd_ingestdir` passent automatiquement `source_path` et `source_modified_at` (mtime fichier)
- **`document_get`** : param√®tre `include_content=False` par d√©faut ‚Üí m√©tadonn√©es sans t√©l√©chargement S3 (rapide). `include_content=True` pour r√©cup√©rer le contenu.

### Chunked Graph Extraction (v0.6.0 ‚Üí v0.6.1)
- **Extraction chunked s√©quentielle** avec contexte cumulatif pour les gros documents
- `extract_with_ontology_chunked()` : d√©coupe si texte > `EXTRACTION_CHUNK_SIZE`
- **v0.6.1** : `EXTRACTION_CHUNK_SIZE` r√©duit de 200K √† **25K chars** (~6K tokens, laisse marge pour prompt+r√©ponse dans les 120K tokens de gpt-oss:120b)
- D√©coupe aux fronti√®res de sections (double saut de ligne), jamais mid-paragraphe
- Chaque chunk re√ßoit la liste compacte des entit√©s/relations des chunks pr√©c√©dents
- Fusion : d√©duplication par (nom+type) pour entit√©s, (from+to+type) pour relations
- R√©silience : si un chunk timeout, on continue avec les suivants
- `build_prompt()` (ontology.py) accepte `cumulative_context` optionnel
- `memory_ingest()` utilise `extract_with_ontology_chunked()` (transparent pour les petits docs)
- **Timeout LLM** : 120s ‚Üí **600s** (10 min par appel, gpt-oss:120b chain-of-thought)
- **Progress callback** : `extract_with_ontology_chunked()` notifie `extraction_start` et `extraction_chunk_done` ‚Üí propag√© via `ctx.info()` au client
- **Documentation** : `DESIGN/chunking_methodology.md` compl√®te

### Stabilisation & Observabilit√© ingestion (v0.6.1)
- **Fix boucle infinie chunker** : `_split_group_with_overlap()` pouvait boucler infiniment quand overlap + phrase > chunk_size ‚Üí vidage overlap forc√© si n√©cessaire
- **Healthcheck Docker** : `python -c "import httpx"` ‚Üí `curl` (√©conomie ~50MB RAM par check)
- **Lib√©ration m√©moire** : `del content_base64` + `del content` + `gc.collect()` dans `memory_ingest()`
- **Monitoring RSS** : chaque √©tape d'ingestion loggue `[RSS=XXmb]`
- **Logs chunker d√©taill√©s** : 3 passes avec section-par-section, flush imm√©diat
- **Progression CLI temps r√©el** : notifications MCP `ctx.info()` ‚Üí monkey-patch `_received_notification` ‚Üí Rich Live display avec barres % extraction + embedding

### Client web graphe am√©lior√© (v0.6.1 ‚Üí v0.6.4)
- **Toggle MENTIONS (üìÑ)** : bouton toggle dans le header pour afficher/masquer les n≈ìuds Document + ar√™tes MENTIONS. `displayOptions.showMentions` contr√¥le le filtrage dans `applyFilters()`. Permet de visualiser uniquement les relations s√©mantiques.
- **Exit isolation avant ASK** : `submitQuestion()` appelle `exitIsolation()` si mode Focus actif ‚Üí plus de filtrage r√©siduel entre deux questions.
- **v0.6.4 Fix toggle Documents en isolation** : test `showMentions` plac√© AVANT le test d'isolation dans `applyFilters()` ‚Äî les carr√©s rouges disparaissent toujours quand le toggle est OFF, m√™me en mode Focus.
- **v0.6.4 Panneau ASK redimensionnable** : poign√©e de drag en haut du panneau, drag vers le haut = panneau grandit. Body scrollable ind√©pendant (flex layout). `setupAskResize()` dans ask.js.
- **v0.6.4 Export HTML** : bouton "üì• Export HTML" apr√®s chaque r√©ponse. G√©n√®re un fichier HTML autonome avec CSS inline, branding Cloud Temple, compatible impression. `exportAnswerHtml()` dans ask.js.
- **v0.6.4 Barre d'actions** : conteneur `.ask-actions` regroupe "Isoler" + "Export HTML" sous la r√©ponse.

### Recherche accent-insensitive fulltext (v0.6.2)
- **Index fulltext Neo4j** avec analyzer `standard-folding` (ASCII folding : √©‚Üíe, √ß‚Üíc, √º‚Üíu)
- `search_entities()` refactoris√© : fulltext Lucene (principal) + CONTAINS (fallback)
- `_search_fulltext()` : requ√™te Lucene avec scoring par pertinence, filtre par memory_id
- `_search_contains()` am√©lior√© : envoie tokens raw (avec accents) ET normalis√©s (sans accents)
- `ensure_fulltext_index()` : lazy init idempotent au premier appel
- `_escape_lucene()` : √©chappe les caract√®res sp√©ciaux Lucene
- "r√©versibilit√©", "reversibilite", "REVERSIBILITE" ‚Üí matchent tous les 3 ‚úÖ

### Recherche et Q&A (v0.5.2)
- Stop words fran√ßais enrichis (~45 mots) filtr√©s dans search_entities
- Tokenisation robuste : `re.findall(r'[a-zA-Z√Ä-√ø]+', ...)` (ponctuation retir√©e)
- Normalisation des accents : `unicodedata.normalize('NFKD', ...)` ‚Üí `"r√©siliation"` matche `"RESILIATION"`
- Recherche AND puis fallback OR dans Neo4j
- **Q&A dual-mode** :
  - **Graph-Guided RAG** : entit√©s trouv√©es ‚Üí RAG filtr√© par doc_ids (pr√©cis)
  - **RAG-only fallback** : 0 entit√©s ‚Üí RAG sur tous les chunks (exhaustif)
  - "Pas d'informations" seulement si NI graphe NI RAG ne trouvent de contexte
- Logs d√©cisionnels complets : tokenisation ‚Üí graphe ‚Üí RAG ‚Üí contexte LLM

## Ce qui reste √† faire üîß

### üî¥ Prioritaire
- [x] **Gestion de l'authentification MCP** ‚Äî tokens avec memory_ids, enforcement, CLI compl√®te ‚úÖ (02/09/2026)

### Court terme
- [x] Git nettoyage complet + purge historique + force push (session 02/09/2026)
- [ ] Rebuild + r√©-ing√©rer CGA/CGV avec nouvelles limites et ontologie
- [ ] V√©rifier extraction exhaustive des articles (23.2 etc.)
- [ ] Ing√©rer plus de documents (CGVU, Contrat Cadre, Convention de Services)

### Moyen terme
- [x] Chunking s√©mantique pour les tr√®s gros documents ‚úÖ (02/09/2026 ‚Äî SemanticChunker)
- [ ] **Git-Sync** ‚Äî Synchronisation automatique m√©moire ‚Üî d√©p√¥t Git. Design termin√© (`DESIGN/GIT_SYNC_DESIGN.md`). Clone initial auto, sync incr√©mental via `git diff`, full-sync, dry-run. Script client `scripts/git_sync.py` + int√©gration CLI Click + Shell. (2026-02-18)
- [ ] Comparer CGA/CGV (outil de diff s√©mantique)
- [ ] Export du graphe (Cypher, JSON-LD, RDF)
- [ ] Am√©liorer la visualisation graph.html (couleurs par type, filtres)

### Long terme
- [x] RAG hybride (graphe + embeddings vectoriels) ‚úÖ (02/09/2026 ‚Äî Graph-Guided RAG Qdrant)
- [ ] Multi-tenant avec isolation des donn√©es
- [ ] Dashboard de monitoring
- [ ] API de merge entre m√©moires

## Bugs connus corrig√©s ‚úÖ
- **force=True cr√©ait des doublons** ‚Üí supprime l'ancien avant de recr√©er
- **Hub "Cloud Temple SAS"** ‚Üí ontologie + prompt anti-hub
- **default.yaml fallback** ‚Üí supprim√©, ontologie obligatoire
- **Shell use avec nom complet** ‚Üí extrait l'ID, valide c√¥t√© serveur
- **Documents tronqu√©s √† 50K** ‚Üí configurable via EXTRACTION_MAX_TEXT_LENGTH
- **generate_answer limit√© √† 1000 tokens** ‚Üí utilise self._max_tokens (60K)
- **Auth 401 sur requ√™tes internes** ‚Üí localhost exempt d'auth
- **Limites hardcod√©es** ‚Üí tout configurable (limit API + shell + .env)
- **Page blanche client web** ‚Üí balise `</title>` tronqu√©e en `</titl` ‚Üí tout le HTML interpr√©t√© comme titre
- **Ponctuation dans tokens de recherche** (v0.5.2) ‚Üí `"r√©siliation?"` avec `?` ne matchait jamais ‚Üí `re.findall` extrait que les lettres
- **Accents non normalis√©s** (v0.5.2) ‚Üí `"r√©siliation"` ne matchait pas `"RESILIATION"` ‚Üí normalisation `unicodedata`
- **Q&A retournait "pas d'infos" sans chercher Qdrant** (v0.5.2) ‚Üí 0 entit√©s graphe = retour imm√©diat ‚Üí ajout fallback RAG-only
- **Qdrant `latest` obsol√®te** (v0.5.2) ‚Üí client 1.16.2 / serveur 1.14.1 ‚Üí image √©pingl√©e `v1.16.2`
- **Boucle infinie chunker OOM** (v0.6.1) ‚Üí `_split_group_with_overlap` : overlap + phrase > chunk_size ‚Üí `i` n'avan√ßait jamais ‚Üí millions de chunks ‚Üí 7.47GB RAM ‚Üí SIGKILL (exit 137) ‚Üí vidage overlap forc√© si n√©cessaire
- **Healthcheck Docker fork Python** (v0.6.1) ‚Üí `python -c "import httpx"` forkait un processus Python complet (~50MB) toutes les 30s ‚Üí remplac√© par `curl`
- **EXTRACTION_CHUNK_SIZE trop grand** (v0.6.1) ‚Üí 200K chars envoy√© en 1 appel LLM saturait le contexte gpt-oss:120b (120K tokens) ‚Üí r√©duit √† 25K chars
- **Recherche "r√©versibilit√©" ‚Üí 0 r√©sultats** (v0.6.2) ‚Üí Python normalisait les accents (`reversibilite`) mais `toLower()` de Neo4j les conservait (`r√©versibilit√©`) ‚Üí `CONTAINS` √©chouait ‚Üí ajout index fulltext `standard-folding` (ASCII folding) + fallback CONTAINS avec double tokens (raw+normalized)
- **RAG quasi inactif seuil 0.65** (v0.6.3) ‚Üí BGE-M3 produit des scores cosinus ~0.55-0.63 pour les meilleurs chunks ‚Üí seuil 0.65 √©liminait 93% des chunks pertinents ‚Üí abaiss√© √† **0.58** apr√®s benchmark comparatif (`scripts/test_rag_thresholds.py`)
- **Toggle Documents inefficace en mode isolation** (v0.6.4) ‚Üí `applyFilters()` : `filterState.isolatedNodes.has(n.id)` retournait `true` avant le test `showMentions` ‚Üí carr√©s rouges Document visibles m√™me avec toggle OFF ‚Üí test `showMentions` d√©plac√© avant le test d'isolation
- **CLI 401 sur serveur de production** (v1.2.1) ‚Üí `scripts/cli/__init__.py` lisait `MCP_SERVER_URL` (pas `MCP_URL`), et Click `envvar="ADMIN_BOOTSTRAP_KEY"` capturait la valeur dev du `.env` local (`admin_bootstrap_key_change_me`) au lieu du token prod ‚Üí ajout `MCP_URL`/`MCP_TOKEN` prioritaires dans `__init__.py` + Click `envvar` en liste ordonn√©e
