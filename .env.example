# =============================================================================
# MCP Memory Service — Configuration
# =============================================================================
# Copiez ce fichier vers .env et remplissez vos valeurs :
#   cp .env.example .env
#
# Toutes les variables sont lues par pydantic-settings (src/mcp_memory/config.py).
# Les valeurs par défaut sont indiquées entre parenthèses.
# =============================================================================

# =============================================================================
# S3 — Stockage objet (documents sources + ontologies)
# =============================================================================
# Endpoint S3 compatible (Cloud Temple, AWS, MinIO, Dell ECS…)
S3_ENDPOINT_URL=https://your-bucket.s3.fr1.cloud-temple.com

# Credentials S3
S3_ACCESS_KEY_ID=your_access_key_id
S3_SECRET_ACCESS_KEY=your_secret_access_key

# Nom du bucket
S3_BUCKET_NAME=your-bucket-name

# Région S3 (défaut: fr1)
# S3_REGION_NAME=fr1

# =============================================================================
# LLMaaS — Service d'IA (extraction d'entités + Q&A)
# =============================================================================
# URL de l'API compatible OpenAI
LLMAAS_API_URL=https://api.ai.cloud-temple.com

# Clé d'API
LLMAAS_API_KEY=your_llmaas_api_key

# Modèle à utiliser (défaut: gpt-oss:120b)
# Modèles testés : gpt-oss:120b, granite3.3:8b
LLMAAS_MODEL=gpt-oss:120b

# Nombre max de tokens par réponse (défaut: 60000)
# gpt-oss:120b utilise du chain-of-thought, nécessite beaucoup de tokens
# LLMAAS_MAX_TOKENS=60000

# Température (défaut: 0.1 — bas pour extraction déterministe)
# LLMAAS_TEMPERATURE=0.1

# Longueur max du texte envoyé au LLM en caractères (défaut: 950000)
# Réduire si le modèle a une fenêtre de contexte plus petite
EXTRACTION_MAX_TEXT_LENGTH=120000

# =============================================================================
# Neo4j — Base de données de graphe
# =============================================================================
# URI de connexion (défaut: bolt://neo4j:7687 pour Docker)
NEO4J_URI=bolt://neo4j:7687

# Identifiants
NEO4J_USER=neo4j
NEO4J_PASSWORD=change_this_password

# Base de données (défaut: neo4j)
# NEO4J_DATABASE=neo4j

# =============================================================================
# Serveur MCP
# =============================================================================
# Port d'écoute (défaut: 8002)
MCP_SERVER_PORT=8002

# Adresse d'écoute (défaut: 0.0.0.0)
# MCP_SERVER_HOST=0.0.0.0

# Mode debug — logs détaillés (défaut: false)
MCP_SERVER_DEBUG=false

# Nom du serveur MCP (défaut: mcp-memory)
# MCP_SERVER_NAME=mcp-memory

# =============================================================================
# Authentification
# =============================================================================
# Clé bootstrap pour créer le premier token d'API.
# À changer impérativement en production !
ADMIN_BOOTSTRAP_KEY=change_me_in_production

# =============================================================================
# Limites et timeouts
# =============================================================================
# Taille max d'un document en Mo (défaut: 50)
# MAX_DOCUMENT_SIZE_MB=50

# Timeout extraction LLM en secondes (défaut: 120)
# EXTRACTION_TIMEOUT_SECONDS=120

# Timeout upload S3 en secondes (défaut: 60)
# S3_UPLOAD_TIMEOUT_SECONDS=60

# Timeout requêtes Neo4j en secondes (défaut: 30)
# NEO4J_QUERY_TIMEOUT_SECONDS=30
